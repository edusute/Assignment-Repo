{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ai03dTasks\n",
    "# Machine Learning: Decision Trees\n",
    "## Train, Evaluate, and Apply the Model\n",
    "\n",
    "**Instructions:**\n",
    "- Complete each task below by running the code cells\n",
    "- Fill in the blanks and answer questions in markdown cells\n",
    "- Save your work when finished\n",
    "- Push this file to your GitHub \"Machine Learning\" Repo under the appropriate folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup: Complete Data Preparation (Lessons 1-3)\n",
    "\n",
    "Run this cell first - it completes all steps from Lessons 3a, 3b, and 3c:\n",
    "- Loads the Titanic dataset\n",
    "- Selects useful features\n",
    "- Handles missing values\n",
    "- Encodes categorical variables\n",
    "- Creates X (features) and y (target)\n",
    "\n",
    "**After running this, you'll be ready to train your model!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tools we need: pandas for data, matplotlib for charts, scikit-learn for ML models\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings  # Suppressing warnings will keep our notebooks clean \n",
    "\n",
    "warnings.filterwarnings('ignore')   # Hides all warning messages\n",
    "\n",
    "# Load the CSV file into a DataFrame so we can work with it in Python\n",
    "df = pd.read_csv(\"Titanic Dataset.csv\")\n",
    "print(f\"✓ Dataset loaded: {df.shape}\")      # Show number of rows and columns\n",
    "\n",
    "# Keep only the columns we need for our model (removes extra/unnecessary data)\n",
    "df = df[['pclass', 'survived', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]\n",
    "print(f\"✓ Features selected: {df.shape[1]} columns\")\n",
    "\n",
    "# Convert `fare` and `age` to a numeric type since they have tripped us up previously (non-numeric values turn into NaN if needed)\n",
    "df[['fare', 'age']] = df[['fare', 'age']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill missing ages/fares with the median and remove rows missing \"embarked\"\n",
    "df['age'].fillna(df['age'].median(), inplace=True)     # Replace missing ages\n",
    "df['fare'].fillna(df['fare'].median(), inplace=True)   # Replace missing fares\n",
    "df.dropna(subset=['embarked'], inplace=True)           # Drop rows missing a category\n",
    "print(f\"✓ Missing values handled: {df.isnull().sum().sum()} remaining\")\n",
    "\n",
    "# Convert text columns (\"sex\", \"embarked\") into numeric dummy variables for ML\n",
    "df = pd.get_dummies(df, columns=['sex', 'embarked'], drop_first=True)\n",
    "print(f\"✓ Categorical variables encoded\")\n",
    "\n",
    "# Split data into features (X) the model uses, and the target (y) we want to predict\n",
    "X = df.drop('survived', axis=1)    # All columns except the answer\n",
    "y = df['survived']                 # The column we want to predict\n",
    "\n",
    "print(f\"\\n✓ Data preparation complete!\")\n",
    "print(f\"X shape: {X.shape} (rows, features)\")   # How many rows/features we have\n",
    "print(f\"y shape: {y.shape} (rows)\")             # Number of target labels\n",
    "print(f\"Feature names: {X.columns.tolist()}\")  # The final features used for ML\n",
    "print(f\"\\nSurvival rate: {y.mean():.2%}\")      # Quick look at target distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do a quick inspection: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Train/Test Split\n",
    "\n",
    "Now we'll split our prepared data into training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Split the Data\n",
    "\n",
    "Split into 80% training and 20% testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use train_test_split to split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    ________, ________,      # X and y\n",
    "    test_size=________,      # 20% for testing (0.2)\n",
    "    random_state=________    # Use 42 for reproducibility\n",
    ")\n",
    "\n",
    "print(\"✓ Data split complete!\")\n",
    "print(f\"Training set: {X_train.shape[0]} passengers ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Testing set: {X_test.shape[0]} passengers ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nTraining survival rate: {y_train.mean():.2%}\")\n",
    "print(f\"Testing survival rate: {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1: How many passengers are in the training set?**\n",
    "\n",
    "A: \n",
    "\n",
    "**Q2: Why do we split the data before training?**\n",
    "\n",
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Create and Train the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Decision Tree model with a limited depth (to prevent overfitting)\n",
    "model = DecisionTreeClassifier(\n",
    "    max_depth=______,      # Limits how deep the tree can grow (set to 4 for now)\n",
    "    random_state=______    # Controls the model's own randomness (different from the split's randomness)\n",
    ")\n",
    "\n",
    "# Train the model: teach it by giving it the training features (X_train) and answers (y_train)\n",
    "model.fit(_____, _____)\n",
    "\n",
    "print(\"✓ Model trained successfully!\")\n",
    "\n",
    "# Show how deep the trained tree grew\n",
    "print(f\"Tree depth: {model.get_depth()}\")\n",
    "\n",
    "# Show how many leaf nodes (final decision points) the tree has\n",
    "print(f\"Number of leaves: {model.get_n_leaves()}\")\n",
    "\n",
    "# Show how many input features the model actually used\n",
    "print(f\"Features used: {model.n_features_in_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3: What does max_depth=4 mean?**\n",
    "\n",
    "A: \n",
    "\n",
    "**Q4: What does the .fit() method do?**\n",
    "\n",
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Make Predictions and Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to predict survival on the test features (X_test)\n",
    "y_pred = model.predict(______)\n",
    "\n",
    "# Compare predictions to actual answers (y_test) and compute accuracy score\n",
    "accuracy = accuracy_score(______, y_pred)\n",
    "\n",
    "print(\"✓ Predictions made!\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")        # Accuracy as a decimal\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")   # Same accuracy as a percentage\n",
    "\n",
    "# Count how many predictions the model got correct\n",
    "correct = (y_pred == y_test).sum()\n",
    "total = len(y_test)\n",
    "print(f\"\\nCorrect predictions: {correct} out of {total}\")\n",
    "\n",
    "# Show the first 10 predictions next to the real answers for a quick check\n",
    "print(\"\\nFirst 10 predictions vs actual:\")\n",
    "comparison = pd.DataFrame({\n",
    "    'Predicted': y_pred[:10],\n",
    "    'Actual': y_test[:10].values,\n",
    "    'Match': ['✓' if p == a else '✗' for p, a in zip(y_pred[:10], y_test[:10])]\n",
    "})\n",
    "print(comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5: What is your model's accuracy as a percentage?**\n",
    "\n",
    "A: \n",
    "\n",
    "**Q6: Is this better than random guessing (50%)?**\n",
    "\n",
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Detailed Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate classification report, use `y_test` and `y_pred`\n",
    "print(\"Classification Report:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(________, ________, target_names=['Died', 'Survived']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Classification Report\n",
    "\n",
    "The table above (output after you run the script) shows how well the model performed for each class (Died vs Survived).\n",
    "\n",
    "| Row / Column | What it means |\n",
    "|--------------|----------------|\n",
    "| **Died** / **Survived** | The two classes the model predicts. Each row shows how well the model did for that specific group. |\n",
    "| **precision** | When the model predicted this class, how often was it correct? |\n",
    "| **recall** | Out of all the real people in this class, how many did the model correctly identify? |\n",
    "| **f1-score** | A single score that combines precision and recall. |\n",
    "| **support** | How many actual examples of that class were in the test data. |\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Rows\n",
    "\n",
    "| Row | What it means |\n",
    "|-----|----------------|\n",
    "| **accuracy** | The overall percent of predictions the model got right. |\n",
    "| **macro avg** | The average of precision/recall/F1 across both classes, treating them equally. |\n",
    "| **weighted avg** | The average of the scores, but weighted based on how many examples each class has. |\n",
    "\n",
    "### Summary\n",
    "These metrics show how well the model performs for each class and overall, helping us see which groups it predicts well and which ones it struggles with.\n",
    "\n",
    "**What is considered good?**  \n",
    "- **0.90–1.00** → Excellent  \n",
    "- **0.80–0.89** → Very good  \n",
    "- **0.70–0.79** → Decent / acceptable  \n",
    "- **Below 0.70** → Needs improvement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7: What is the precision for 'Survived'?**\n",
    "\n",
    "A: \n",
    "\n",
    "**Q8: What is the recall for 'Survived'?**\n",
    "\n",
    "A: \n",
    "\n",
    "**Q9: In your own words, explain what precision means:**\n",
    "\n",
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Feature Importance\n",
    "\n",
    "Feature importance tells us which input features (age, fare, pclass, etc.) the decision tree relied on the most when making predictions.  \n",
    "Higher importance values mean the feature contributed more to the model’s decisions.  \n",
    "The total importance adds up to about 1.0, showing how the model distributes its “attention” across all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame showing each feature and how important it was in the model\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,                 # The names of all input features\n",
    "    'importance': model.feature_importances_  # How much each feature helped the tree make decisions\n",
    "}).sort_values('importance', ascending=False)  # Sort so the most important features appear first\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Print the DataFrame in a clean, readable format (no row numbers)\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "# Show the total importance (should be close to 1.0)\n",
    "print(f\"\\nTotal importance: {importance_df['importance'].sum():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10: Which feature is most important?**\n",
    "\n",
    "A: \n",
    "\n",
    "**Q11: Does this make sense historically (women and children first)?**\n",
    "\n",
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Visualize Feature Importance\n",
    "The code below uses Matplotlib to create the feature-importance chart. All the `plt` commands come from the Matplotlib package we imported at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))                            # Start a new chart and set the overall width/height\n",
    "plt.barh(importance_df['feature'],\n",
    "         importance_df['importance'],\n",
    "         color='steelblue')                            # Draw a horizontal bar chart using our features and their scores\n",
    "plt.xlabel('Importance', fontsize=12)                  # Label the x-axis so we know what the numbers represent\n",
    "plt.ylabel('Feature', fontsize=12)                     # Label the y-axis with each feature’s name\n",
    "plt.title('Feature Importance in Decision Tree Model',\n",
    "          fontsize=14, fontweight='bold')              # Add a clear title to explain what the chart shows\n",
    "plt.tight_layout()                                     # Fix spacing so labels don’t overlap or get cut off\n",
    "plt.show()                                             # Display the final chart on the screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Visualize the Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Create Tree Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Read the Decision Tree (Key)\n",
    "\n",
    "- **Colors:**  \n",
    "  - *Blue* = model leans toward **Survived**  \n",
    "  - *Orange* = model leans toward **Died**  \n",
    "  - Darker color = stronger confidence; lighter color = more mixed data  \n",
    "\n",
    "- **Split Rule (top line):**  \n",
    "  The condition used to divide the data (e.g., `sex_male <= 0.5`).  \n",
    "  Left branch = condition is True; right branch = condition is False.\n",
    "\n",
    "- **gini:**  \n",
    "  A measure of how mixed the node is.  \n",
    "  - 0.0 = perfectly pure (all the same class)  \n",
    "  - Higher values = more mixed (less certain)\n",
    "\n",
    "- **samples:**  \n",
    "  How many passengers reached that point in the tree.\n",
    "\n",
    "- **value = [Died, Survived]:**  \n",
    "  The number of passengers from each class in the node.\n",
    "\n",
    "- **class = … :**  \n",
    "  The predicted class for that node (whichever has more samples).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create tree visualization\n",
    "plt.figure(figsize=(20, 10))  # Try (20, 10)\n",
    "plot_tree(\n",
    "    model,                           # The trained model\n",
    "    feature_names=X.columns,         # X.columns\n",
    "    class_names=['Died', 'Survived'],\n",
    "    filled=True,                     # Color nodes by prediction\n",
    "    rounded=True,                    # Rounded boxes\n",
    "    fontsize=10\n",
    ")\n",
    "plt.title(\"Titanic Survival Decision Tree\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12: What is the first question (root node) the tree asks?**\n",
    "\n",
    "A: \n",
    "\n",
    "**Q13: What color represents 'Survived' predictions?**\n",
    "\n",
    "A: \n",
    "\n",
    "**Q14: Find one decision path from root to leaf and describe it:**\n",
    "\n",
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Make New Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Create Test Scenarios\n",
    "\n",
    "Feature order: `[pclass, age, sibsp, parch, fare, sex_male, embarked_Q, embarked_S]`\n",
    "\n",
    "Remember:\n",
    "- pclass: 1, 2, or 3\n",
    "- sex_male: 1=male, 0=female\n",
    "- embarked_Q: 1=Queenstown, 0=not\n",
    "- embarked_S: 1=Southampton, 0=not\n",
    "- If both Q and S are 0, passenger embarked at Cherbourg (C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: Poor young man in 3rd class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: 3rd class, 25yo male, no family, low fare, embarked at S\n",
    "passenger1 = [[3, 25, 0, 0, 7.25, 1, 0, 1]]\n",
    "\n",
    "# Make prediction\n",
    "pred = model.predict(passenger1)\n",
    "prob = model.predict_proba(passenger1)\n",
    "\n",
    "print(\"Scenario 1: Poor young man in 3rd class\")\n",
    "print(f\"Prediction: {'Survived' if pred[0] == 1 else 'Died'}\")\n",
    "print(f\"Survival probability: {prob[0][1]:.2%}\")\n",
    "print(f\"Death probability: {prob[0][0]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Wealthy young woman in 1st class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to fill in the passenger data\n",
    "We must list the values in the same order as the model’s feature columns:\n",
    "\n",
    "[pclass, age, sibsp, parch, fare, sex_male, embarked_Q, embarked_S]\n",
    "\n",
    "Then fill in each value:\n",
    "- pclass = 1 (1st class)\n",
    "- age = 25\n",
    "- sibsp = 0 (no siblings/spouse)\n",
    "- parch = 0 (no parents/children)\n",
    "- fare = 100\n",
    "- sex_male = 0 (female)\n",
    "- embarked_Q = 0 (did not embark at Queenstown)\n",
    "- embarked_S = 1 (embarked at Southampton)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create passenger: 1st class, 25yo female, no family, high fare ($100), embarked at S\n",
    "# Hint: sex_male=0 for female\n",
    "woman_1st = [[________, ________, ________, ________, ________, ________, ________, ________]]\n",
    "\n",
    "pred = model.predict(woman_1st)\n",
    "prob = model.predict_proba(woman_1st)\n",
    "\n",
    "print(\"Scenario 2: Wealthy young woman in 1st class\")\n",
    "print(f\"Prediction: {'Survived' if pred[0] == 1 else 'Died'}\")\n",
    "print(f\"Survival probability: {prob[0][1]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3: Young boy in 3rd class with family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create passenger: 3rd class, 5yo male, 1 sibling, 2 parents, medium fare ($20), embarked at S\n",
    "boy_3rd = [[________, ________, ________, ________, ________, ________, ________, ________]]\n",
    "\n",
    "pred = model.predict(boy_3rd)\n",
    "prob = model.predict_proba(boy_3rd)\n",
    "\n",
    "print(\"Scenario 3: Young boy with family\")\n",
    "print(f\"Prediction: {'Survived' if pred[0] == 1 else 'Died'}\")\n",
    "print(f\"Survival probability: {prob[0][1]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 4: Elderly man in 1st class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create passenger: 1st class, 65yo male, no family, very high fare ($500), embarked at C\n",
    "# Hint: embarked at C means embarked_Q=0 and embarked_S=0\n",
    "man_1st_elderly = [[________, ________, ________, ________, ________, ________, ________, ________]]\n",
    "\n",
    "pred = model.predict(man_1st_elderly)\n",
    "prob = model.predict_proba(man_1st_elderly)\n",
    "\n",
    "print(\"Scenario 4: Wealthy elderly man in 1st class\")\n",
    "print(f\"Prediction: {'Survived' if pred[0] == 1 else 'Died'}\")\n",
    "print(f\"Survival probability: {prob[0][1]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Reflection Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15: Which factors seemed most important for survival based on your scenarios?**\n",
    "\n",
    "A: \n",
    "\n",
    "**Q16: Did the model's predictions match the historical \"women and children first\" policy?**\n",
    "\n",
    "A: \n",
    "\n",
    "**Q17: Were any predictions surprising? Why?**\n",
    "\n",
    "A: \n",
    "\n",
    "**Q18: How does visualizing the tree help you understand the model?**\n",
    "\n",
    "A: \n",
    "\n",
    "**Q19: What are some real-world applications where decision trees could be useful?**\n",
    "\n",
    "A: \n",
    "\n",
    "**Q20: What was the most challenging part of this machine learning project?**\n",
    "\n",
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Different Tree Depths\n",
    "\n",
    "Train models with different max_depth values and compare their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train models with max_depth of 3, 4, 5, 10, and None (unlimited)\n",
    "# Compare their training and testing accuracy\n",
    "\n",
    "depths = [3, 4, 5, 10, None]\n",
    "results = []\n",
    "\n",
    "for depth in depths:\n",
    "    # Train model\n",
    "    model_temp = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    model_temp.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_acc = accuracy_score(y_train, model_temp.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, model_temp.predict(X_test))\n",
    "    \n",
    "    results.append({\n",
    "        'max_depth': depth,\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'difference': train_acc - test_acc\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"\\nNote: Large difference between train and test accuracy suggests overfitting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Unit Complete!\n",
    "\n",
    "**Congratulations! You've completed the Machine Learning with Decision Trees unit!**\n",
    "\n",
    "**You've learned:**\n",
    "- Complete ML pipeline from raw data to predictions\n",
    "- Data loading, cleaning, and preprocessing\n",
    "- Feature engineering (one-hot encoding)\n",
    "- Train/test splitting for honest evaluation\n",
    "- Training decision tree classifiers\n",
    "- Evaluating with accuracy, precision, recall, F1\n",
    "- Interpreting feature importance\n",
    "- Visualizing decision trees\n",
    "- Making predictions on new data\n",
    "\n",
    "**This workflow applies to ALL machine learning projects!**\n",
    "\n",
    "**Next steps we will take:**\n",
    "- Try this pipeline with different datasets\n",
    "- Explore other algorithms (Random Forests, Logistic Regression, etc.)\n",
    "- Learn about feature engineering\n",
    "- Study hyperparameter tuning\n",
    "- Practice with real-world problems!\n",
    "\n",
    "Save this notebook and push to GitHub. Great work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
